# MCP Filesystem Assistant with Web UI

This project is a local AI assistant that lets you:

âœ… Query and analyze files stored in `/workspace`  
âœ… Upload and delete files via a modern web interface  
âœ… Use GPT-4o to summarize or answer questions about your files  
âœ… Easily extend to Azure, Kubernetes, or more secure setups

---

## âœ¨ Features

- ğŸ“‚ List and delete files in your workspace
- ğŸ“ Upload files via a drag-and-drop UI
- ğŸ’¬ Chat with GPT-4o about file contents
- âš¡ Clean, mobile-friendly frontend
- ğŸ” (Optional) Add authentication for security

---

## ğŸ“‚ Project Structure

```
Custom-MCP-Server/
â”œâ”€â”€ agent/                  # Node agent (GPT + tools logic)
â”‚   â””â”€â”€ index.js
â”œâ”€â”€ tools/
â”‚   â””â”€â”€ filesystem/
â”‚       â””â”€â”€ server.js       # MCP-compatible Filesystem Server
â”œâ”€â”€ workspace/              # Files you want the assistant to access
â”‚   â””â”€â”€ test.txt
â”œâ”€â”€ web/                    # React frontend
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ components/
â”‚           â””â”€â”€ ChatInterface.js
â”œâ”€â”€ server.js               # Express backend exposing /chat and /upload
â”œâ”€â”€ .env
â”œâ”€â”€ package.json
```

---

## âš™ï¸ Prerequisites

- Node.js v18+
- An OpenAI API key

---

## ğŸ›  Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/mcp-assistant
   cd mcp-assistant
   ```

2. Install dependencies (root):

   ```bash
   npm install
   ```

3. Install frontend dependencies:

   ```bash
   cd web
   npm install
   ```

4. Create a `.env` file in the root:

   ```env
   OPENAI_API_KEY=your_openai_api_key_here
   MCP_FILESYSTEM_URL=http://localhost:4001
   ```

---

## ğŸš€ Running the App

Open **3 terminals**:

**Terminal 1 â€“ MCP Filesystem Server**

```bash
cd tools/filesystem
node server.js
```

**Terminal 2 â€“ Express Backend**

```bash
node server.js
```

**Terminal 3 â€“ React Frontend**

```bash
cd web
npm start
```

Frontend: [http://localhost:3000](http://localhost:3000)  
Backend API: [http://localhost:4000](http://localhost:4000)  
Filesystem API: [http://localhost:4001](http://localhost:4001)

---

## ğŸ§  How It Works

1. You ask a question in the web chat.
2. The backend (`server.js`) calls GPT-4o with tool definitions.
3. GPT either:
   - Replies directly, or
   - Calls tools (`read_file`, `list_files`) via MCP.
4. If a tool call is needed, the backend:
   - Requests file content or file list from the filesystem server.
   - Sends the result back into GPT for a final answer.
5. The frontend displays GPT's reply.

---

## ğŸ–¼ Web UI Overview

- Clean, responsive chat interface
- Upload files into `/workspace`
- List and delete workspace files inline
- Works great on desktop & mobile

---

## ğŸ’¡ Tips

- All files must be in `/workspace` to be accessible.
- To avoid CORS issues, always start all servers and use the correct ports.
- You can customize styles with Tailwind CSS or your own CSS.

---

## âœ… Next Steps

- Add authentication with API keys or sessions.
- Deploy to Azure or Kubernetes.
- Extend tool capabilities (e.g., CSV analysis).
- Persist chat history.

---

## License

MIT License
